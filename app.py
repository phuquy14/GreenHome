import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. Cáº¤U HÃŒNH API (CHUáº¨N CHO WEB) ---
try:
    # Láº¥y key tá»« "KÃ©t sáº¯t" khi cháº¡y trÃªn máº¡ng
    api_key = st.secrets["GOOGLE_API_KEY"]
except:
    # ğŸ‘‡ DÃN API KEY Cá»¦A Báº N VÃ€O DÃ’NG DÆ¯á»šI Äá»‚ CHáº Y TRÃŠN MÃY TÃNH ğŸ‘‡
    api_key = ""

genai.configure(api_key=api_key)

st.set_page_config(
    page_title="GreenHome AI",
    page_icon="ğŸŒ±",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- 2. Bá»˜ NÃƒO GREENHOME (THEO TÃ€I LIá»†U SYSTEM PROMPT) ---
system_instruction = """
Báº N LÃ€: GreenHome ğŸŒ± - Trá»£ lÃ½ nÄƒng lÆ°á»£ng xanh thÃ¢n thiá»‡n.
Má»¤C TIÃŠU: GiÃºp giáº£m phÃ¡t tháº£i CO2 vÃ  tiáº¿t kiá»‡m chi phÃ­ Ä‘iá»‡n nÄƒng[cite: 4].

QUY Táº®C TRáº¢ Lá»œI:
1. LUÃ”N QUY Äá»”I CO2: DÃ¹ng há»‡ sá»‘ 0.72kg CO2/kWh. So sÃ¡nh trá»±c quan (vÃ­ dá»¥: tÆ°Æ¡ng Ä‘Æ°Æ¡ng lÃ¡i xe X km, hoáº·c Y cÃ¢y xanh)[cite: 17, 18].
2. ÄÃNH GIÃ Má»¨C Äá»˜:
   - < 150 kWh: Tháº¥p (Khen ngá»£i)[cite: 55].
   - 150-300 kWh: Trung bÃ¬nh[cite: 56].
   - 300-500 kWh: HÆ¡i cao[cite: 57].
   - > 500 kWh: Cao (Cáº£nh bÃ¡o)[cite: 58].
3. Lá»œI KHUYÃŠN: ÄÆ°a ra 3 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ (Äiá»u hÃ²a, Tá»§ láº¡nh, ÄÃ¨n LED...) kÃ¨m Æ°á»›c tÃ­nh tiá»n tiáº¿t kiá»‡m[cite: 60, 63].

CHáº¾ Äá»˜ LÃI CHUYá»†N (Smart Steering):
- Náº¿u ngÆ°á»i dÃ¹ng há»i chuyá»‡n ngoÃ i lá» (tÃ¬nh cáº£m, vui chÆ¡i...): HÃ£y Ä‘á»“ng cáº£m ngáº¯n gá»n, sau Ä‘Ã³ dÃ¹ng sá»± hÃ i hÆ°á»›c Ä‘á»ƒ lÃ¡i vá» chá»§ Ä‘á» tiáº¿t kiá»‡m nÄƒng lÆ°á»£ng.
"""

model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    system_instruction=system_instruction
)

# --- 3. GIAO DIá»†N DARK MODE ---
st.markdown("""
<style>
    .stApp {background-color: #131314; color: #E3E3E3;}
    header, footer, #MainMenu {visibility: hidden;}
    .stChatInputContainer textarea {background-color: #1E1F20; color: white; border-radius: 25px; border: 1px solid #444746;}
    [data-testid="stPopover"] button {border-radius: 50%; width: 40px; height: 40px; border: 1px solid #444746; background-color: #1E1F20; color: #A8C7FA;}
    table {width: 100%; border-collapse: collapse; color: #E3E3E3;}
    th {background-color: #2E7D32; color: white;}
    td {border-bottom: 1px solid #444;}
</style>
""", unsafe_allow_html=True)

# --- 4. KHá»I Táº O Lá»œI CHÃ€O (ÄÃƒ Sá»¬A Lá»–I) ---
if "messages" not in st.session_state:
    # Ná»™i dung chÃ o chuáº©n theo ká»‹ch báº£n [cite: 29-34]
    welcome_msg = """Xin chÃ o! MÃ¬nh lÃ  **GreenHome** ğŸŒ± - trá»£ lÃ½ nÄƒng lÆ°á»£ng xanh cá»§a báº¡n!
    
HÃ£y gá»­i cho mÃ¬nh áº£nh hÃ³a Ä‘Æ¡n tiá»n Ä‘iá»‡n ğŸ“¸ hoáº·c nháº­p sá»‘ Ä‘iá»‡n tiÃªu thá»¥, mÃ¬nh sáº½ giÃºp báº¡n:

* ğŸ“Š **TÃ­nh lÆ°á»£ng CO2 phÃ¡t tháº£i**
* ğŸ’° **Æ¯á»›c tÃ­nh chi phÃ­ & Tiáº¿t kiá»‡m**
* ğŸŒ **ÄÆ°a ra lá»i khuyÃªn cá»¥ thá»ƒ**

Sáºµn sÃ ng chÆ°a nÃ o? ğŸ˜Š"""
    
    st.session_state.messages = [
        {"role": "model", "content": welcome_msg}
    ]

if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = 0

# --- 5. GIAO DIá»†N CHÃNH ---
st.markdown("<h3 style='text-align: center; color: #81C995;'>ğŸŒ± GreenHome</h3>", unsafe_allow_html=True)

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. Xá»¬ LÃ NHáº¬P LIá»†U ---
input_container = st.container()
with input_container:
    col1, col2 = st.columns([1, 10])
    with col1:
        with st.popover("â•"):
            uploaded_file = st.file_uploader("Chá»n áº£nh", type=["jpg", "png"], key=f"uploader_{st.session_state.uploader_key}")
    with col2:
        if uploaded_file: st.caption(f"âœ… ÄÃ£ chá»n: {uploaded_file.name}")

if prompt := st.chat_input("Nháº¯n tin cho GreenHome..."):
    # 1. User gá»­i tin
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
        if uploaded_file: st.image(Image.open(uploaded_file), width=200)

    # 2. Bot tráº£ lá»i
    with st.chat_message("model"):
        msg_box = st.empty()
        full_text = ""
        try:
            history_gemini = []
            for msg in st.session_state.messages[:-1]:
                role = "user" if msg["role"] == "user" else "model"
                history_gemini.append({"role": role, "parts": [msg["content"]]})
            
            chat = model.start_chat(history=history_gemini)
            
            if uploaded_file:
                # Prompt kÃ­ch hoáº¡t quy trÃ¬nh phÃ¢n tÃ­ch chuáº©n [cite: 41-53]
                img_prompt = prompt + "\n\n(Há»‡ thá»‘ng: HÃ£y phÃ¢n tÃ­ch hÃ³a Ä‘Æ¡n nÃ y. TrÃ­ch xuáº¥t sá»‘ kWh, tÃ­nh CO2, Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ (Tháº¥p/TB/Cao) vÃ  Ä‘Æ°a ra 3 lá»i khuyÃªn tiáº¿t kiá»‡m cá»¥ thá»ƒ theo chuáº©n GreenHome)"
                response = chat.send_message([img_prompt, Image.open(uploaded_file)], stream=True)
                st.session_state.uploader_key += 1
            else:
                response = chat.send_message(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_text += chunk.text
                    msg_box.markdown(full_text + "â–Œ")
            
            msg_box.markdown(full_text)
            st.session_state.messages.append({"role": "model", "content": full_text})
            
            if uploaded_file: st.rerun()
        except Exception as e:
            st.error(f"Lá»—i: {e}")