import streamlit as st
import google.generativeai as genai
from PIL import Image
import random

# --- 1. Cáº¤U HÃŒNH API ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except:
    # XÃ“A KEY THáº¬T ÄI, Äá»‚ TRá»NG NHÆ¯ THáº¾ NÃ€Y
    api_key = ""

genai.configure(api_key=api_key)

st.set_page_config(
    page_title="GreenHome AI",
    page_icon="ğŸŒ±",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- 2. Bá»˜ NÃƒO "SIÃŠU LÃI CHUYá»†N" ---
system_instruction = """
Báº N LÃ€: GreenHome ğŸŒ± - Trá»£ lÃ½ áº£o "cuá»“ng" Tiáº¿t kiá»‡m Ä‘iá»‡n & Sá»‘ng xanh.
Má»¤C TIÃŠU DUY NHáº¤T: GiÃºp ngÆ°á»i dÃ¹ng giáº£m hÃ³a Ä‘Æ¡n Ä‘iá»‡n vÃ  giáº£m CO2.

QUY Táº®C á»¨NG Xá»¬:
1. Náº¾U Há»I Vá»€ ÄIá»†N/HÃ“A ÄÆ N:
   - [cite_start]Tráº£ lá»i chuyÃªn nghiá»‡p, tÃ­nh CO2 (0.72kg/kWh), Ä‘Æ°a lá»i khuyÃªn cá»¥ thá»ƒ[cite: 33, 34, 48].

2. Náº¾U Há»I CHUYá»†N NGOÃ€I Lá»€ (TÃ¬nh yÃªu, Ä‚n uá»‘ng...):
   - BÆ°á»›c 1: Äá»“ng cáº£m ngáº¯n gá»n.
   - BÆ°á»›c 2: LÃI NGAY Láº¬P Tá»¨C vá» chá»§ Ä‘á» tiáº¿t kiá»‡m Ä‘iá»‡n má»™t cÃ¡ch hÃ i hÆ°á»›c.

VÃ Dá»¤:
- User: "TÃ´i nhá»› ngÆ°á»i yÃªu."
  -> Bot: "Hiá»ƒu mÃ ! NhÆ°ng nhá»› nhung cÅ©ng tá»‘n nÄƒng lÆ°á»£ng nhÆ° bÃ³ng Ä‘Ã¨n sá»£i Ä‘á»‘t váº­y. â¤ï¸â€ğŸ”¥ Thay vÃ¬ ngá»“i buá»“n, hÃ£y táº¯t Ä‘Ã¨n, má»Ÿ cá»­a sá»• hÃ³ng giÃ³ trá»i. Vá»«a chill, láº¡i vá»«a tiáº¿t kiá»‡m tiá»n Ä‘iá»‡n Ä‘á»ƒ dÃ nh Ä‘i háº¹n hÃ²! ğŸ’¡ğŸŒ±"
"""

model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    system_instruction=system_instruction
)

# --- 3. GIAO DIá»†N DARK MODE ---
st.markdown("""
<style>
    .stApp {background-color: #131314; color: #E3E3E3;}
    header, footer, #MainMenu {visibility: hidden;}
    .stChatInputContainer textarea {background-color: #1E1F20; color: white; border-radius: 25px; border: 1px solid #444746;}
    [data-testid="stPopover"] button {border-radius: 50%; width: 40px; height: 40px; border: 1px solid #444746; background-color: #1E1F20; color: #A8C7FA;}
    table {width: 100%; border-collapse: collapse; color: #E3E3E3;}
    th {background-color: #2E7D32; color: white;}
    td {border-bottom: 1px solid #444;}
</style>
""", unsafe_allow_html=True)

# --- 4. KHá»I Táº O (CHÃ€O NGáºªU NHIÃŠN) ---
if "messages" not in st.session_state:
    greetings = [
        "ChÃ o báº¡n! GreenHome Ä‘Ã¢y ğŸŒ±. [cite_start]Gá»­i hÃ³a Ä‘Æ¡n Ä‘iá»‡n Ä‘á»ƒ mÃ¬nh tÃ­nh CO2 giÃºp nhÃ©! [cite: 58, 60]",
        "Hello! âš¡ Tiáº¿t kiá»‡m Ä‘iá»‡n hÃ´m nay, xanh TrÃ¡i Äáº¥t ngÃ y mai. Báº¡n cáº§n mÃ¬nh tÆ° váº¥n gÃ¬?",
        "GreenHome xin chÃ o! ğŸŒ Äá»«ng Ä‘á»ƒ hÃ³a Ä‘Æ¡n lÃ m báº¡n 'Ä‘au vÃ­'. Chá»¥p áº£nh gá»­i Ä‘Ã¢y nÃ o!",
        "Xin chÃ o Ä‘á»“ng chÃ­ 'Sá»‘ng Xanh'! ğŸ‘‹ HÃ´m nay chÃºng ta giáº£m bao nhiÃªu sá»‘ Ä‘iá»‡n Ä‘Ã¢y?"
    ]
    st.session_state.messages = [{"role": "model", "content": random.choice(greetings)}]

if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = 0

# --- 5. GIAO DIá»†N CHÃNH ---
st.markdown("<h3 style='text-align: center; color: #81C995;'>ğŸŒ± GreenHome</h3>", unsafe_allow_html=True)

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. Xá»¬ LÃ NHáº¬P LIá»†U ---
input_container = st.container()
with input_container:
    col1, col2 = st.columns([1, 10])
    with col1:
        with st.popover("â•"):
            uploaded_file = st.file_uploader("Chá»n áº£nh", type=["jpg", "png"], key=f"uploader_{st.session_state.uploader_key}")
    with col2:
        if uploaded_file: st.caption(f"âœ… ÄÃ£ chá»n: {uploaded_file.name}")

if prompt := st.chat_input("Nháº¯n tin cho GreenHome..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
        if uploaded_file: st.image(Image.open(uploaded_file), width=200)

    with st.chat_message("model"):
        msg_box = st.empty()
        full_text = ""
        try:
            history_gemini = []
            for msg in st.session_state.messages[:-1]:
                role = "user" if msg["role"] == "user" else "model"
                history_gemini.append({"role": role, "parts": [msg["content"]]})
            
            chat = model.start_chat(history=history_gemini)
            
            if uploaded_file:
                # [cite_start]Prompt ngáº§m xá»­ lÃ½ áº£nh theo ká»‹ch báº£n [cite: 66, 71]
                img_prompt = prompt + "\n\n(Há»‡ thá»‘ng: HÃ£y phÃ¢n tÃ­ch áº£nh nÃ y. Náº¿u lÃ  hÃ³a Ä‘Æ¡n, trÃ­ch xuáº¥t sá»‘ liá»‡u vÃ  tÃ­nh CO2. Náº¿u khÃ¡c, hÃ£y lÃ¡i cÃ¢u chuyá»‡n vá» tiáº¿t kiá»‡m Ä‘iá»‡n)"
                response = chat.send_message([img_prompt, Image.open(uploaded_file)], stream=True)
                st.session_state.uploader_key += 1
            else:
                response = chat.send_message(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_text += chunk.text
                    msg_box.markdown(full_text + "â–Œ")
            
            msg_box.markdown(full_text)
            st.session_state.messages.append({"role": "model", "content": full_text})
            
            if uploaded_file: st.rerun()
        except Exception as e:
            st.error(f"Lá»—i: {e}")